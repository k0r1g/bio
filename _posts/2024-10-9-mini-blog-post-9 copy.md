---
layout: post
title: "Mini Blog Post 9: AI for Science"
date: 2024-10-09
categories: blog
author: Kori Rogers
tags: none
---
Below are some ramblings about AI sweeping two Nobel Prizes & how it could inspire AI for science startups.

Geoffrey Hinton, awarded a Nobel Prize in Physics. 

Demis Hassabis, awarded a Nobel Prize in Chemistry. 

They are not men of Chemistry or Physics. Their work is AI. 

Sam Altman himself has stated that what he is most excited about is the potential of AI to contribute to science. Demis Hassabis has said a similar thing.

A tide is shifting, can you feel it?

Ask yourself one thing- will these be the last Nobel Prizes awarded for contributions to AI? No, I don't think so. More will come. 

Let's ask another question. *When will the first Nobel Prize be awarded to an AI?* 

Imagine a startup who's mission is to win a Nobel Prize. Specifically, who's mission is to build the first AI that will win a Nobel Prize. 

It would be an R&D company, whose purpose is to invent new technologies. Yet, research is expensive- an incredibly profitable business is needed to fund research. 

Bell Labs, Rand Corporation. The Manhattan Project. The startup would be of that cloth. 

There are many ways it could point it's focus: 

It's first goal could be to publish a scientific paper written fully by an AI. However, this would not generate money, and money is needed to fund future research. 

Alternatively, it could build a tool used by scientists. For example, a small tool to enable scientists to publish their work faster. This seems like an extremely unimpactful & small business- but it could be a powerful wedge as the startup adds more features. 

**Consider the Manhattan Project:**
"The Manhattan Project was a research and development program undertaken during World War II to produce the first nuclear weapons." (The first line on Wikipedia)

A single goal- a start & an end. There is an end goal. I like that for a company- to give an end goal, it would be so different from other companies, to establish a point at which the company can say "we are done". OpenAI has that in some sense, it's murkier now but for the longest time AGI felt like a discrete end goal for the company. 

The Manhattan Project was also built around a particular period of time "World War II"- it creates a sense of urgency, and it signifies the 'why now' of the company. For the current age it could be "The Birth of AGI". An interesting point to consider is that joke that nobody called WWI, World War I when it was happening, because that would only make sense until World War II happened. It takes a certain situational awareness to understand the times we are living in, and a foresight as to what is to come. We are in the "Prenatal Era of AGI"- are we in the second or third trimester? 

**A tweet from an ex-DeepMind intern**
*During my internship at DeepMind, Demis met with all the interns. When asked about the company’s goal, I vividly remember him saying, “winning multiple Nobel prizes.” I was shocked at the time, but now, just 7 years later, part of that mission is already accomplished. Eager to see the rest unfold.*

It is important to note that applying AI to scientic discovery is different from applying AI to R&D. R = Science, D = Engineering. The latter is more interesting- my bias for practical application is showing. 

The startup could built an AutoRAND- a way to automate R&D with AI. For this startup to make sense, one would have to believe that AGI is not sufficient to increase the rate of scientific discovery. It could be about some local data need, or some other deficiency. It's not obvious to me now. 

**AI & the Nobel Peace Prize**
When will the first Nobel Peace prize be awarded for work done on AI Safety?

**Is solving intelligence the only meaningful thing to work on?**
DeepMind's mission is, according to Hassabis, to: "solve intelligence" and then use intelligence "to solve everything else". 

I've brought this up before, but if getting to AGI frictionlessly leads to getting to ASI (aka the fast take-off), and ASI solves all of humanity's problems, then does make a lot of other work meaningless. It's like Popper's theory around paradigm shifts in science, imagine working on a prior paradigm of science- building incremental progress, and someone else discovers a new paradigm that makes all of your work obsolete. 

This is the risk. I'd rather gamble on this new paradigm. An essay awaits on whether there is anything else meaningful to work on than ASI- I haven't started on it yet, I suppose I'm waiting for intuition on what it could be before I write the essay, but I suppose I should start and learn along the way. 

[back]({{ site.url }})